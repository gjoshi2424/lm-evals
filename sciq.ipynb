{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfz6RYYMKSUz0UQ17nDC64"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import transformers\n",
        "import torch\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "Z0B91ncvjuMn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NC-VakBqiA6Q"
      },
      "outputs": [],
      "source": [
        "#Download dataset from HF\n",
        "dataset = load_dataset('sciq', split='test')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get model, tokenizer, and max_length\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained('gpt2')\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained('gpt2')\n",
        "max_length = tokenizer.model_max_length\n"
      ],
      "metadata": {
        "id": "qbiDznpolbdJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data = dataset[0]\n",
        "#print(sample_data)\n",
        "question =  sample_data['question']\n",
        "print(f\"{question}\\n\")\n",
        "distractors = [sample_data['distractor3'], sample_data['distractor2'], sample_data['distractor1']]\n",
        "print(f\"{distractors}\\n\")\n",
        "answer = sample_data['correct_answer']\n",
        "print(f\"{answer}\\n\")\n",
        "support = sample_data['support']\n",
        "print(f\"{support}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crinFHoolCVT",
        "outputId": "c6938b01-b145-4d89-cbb3-0402ff4e8c9b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compounds that are capable of accepting electrons, such as o 2 or f2, are called what?\n",
            "\n",
            "['residues', 'Oxygen', 'antioxidants']\n",
            "\n",
            "oxidants\n",
            "\n",
            "Oxidants and Reductants Compounds that are capable of accepting electrons, such as O 2 or F2, are calledoxidants (or oxidizing agents) because they can oxidize other compounds. In the process of accepting electrons, an oxidant is reduced. Compounds that are capable of donating electrons, such as sodium metal or cyclohexane (C6H12), are calledreductants (or reducing agents) because they can cause the reduction of another compound. In the process of donating electrons, a reductant is oxidized. These relationships are summarized in Equation 3.30: Equation 3.30 Saylor URL: http://www. saylor. org/books.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompts(data):\n",
        "  support = data['support']\n",
        "  question = data['question']\n",
        "  distractors = [data['distractor3'], data['distractor2'], data['distractor1']]\n",
        "  answer = data['correct_answer']\n",
        "  prompts = []\n",
        "\n",
        "  #Create prompt for answer\n",
        "  promptInstance = {\n",
        "      'context': support + '\\nquestion: ' + question + ' \\nanswer:',\n",
        "      'continuation': answer\n",
        "  }\n",
        "  prompts.append(promptInstance)\n",
        "  # Create prompts for each distractor\n",
        "  for distractor in distractors:\n",
        "    promptInstance = {\n",
        "        'context': support + '\\nquestion: ' + question + ' \\nanswer:',\n",
        "        'continuation': distractor\n",
        "    }\n",
        "    prompts.append(promptInstance)\n",
        "\n",
        "  return prompts\n",
        "\n",
        "prompts = generate_prompts(sample_data)\n",
        "print(prompts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl1OENfRm8d2",
        "outputId": "3c6ff241-9b31-42a6-eda8-00d38a01a89c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'context': 'Oxidants and Reductants Compounds that are capable of accepting electrons, such as O 2 or F2, are calledoxidants (or oxidizing agents) because they can oxidize other compounds. In the process of accepting electrons, an oxidant is reduced. Compounds that are capable of donating electrons, such as sodium metal or cyclohexane (C6H12), are calledreductants (or reducing agents) because they can cause the reduction of another compound. In the process of donating electrons, a reductant is oxidized. These relationships are summarized in Equation 3.30: Equation 3.30 Saylor URL: http://www. saylor. org/books.\\nquestion: Compounds that are capable of accepting electrons, such as o 2 or f2, are called what? \\nanswer:', 'continuation': 'oxidants'}, {'context': 'Oxidants and Reductants Compounds that are capable of accepting electrons, such as O 2 or F2, are calledoxidants (or oxidizing agents) because they can oxidize other compounds. In the process of accepting electrons, an oxidant is reduced. Compounds that are capable of donating electrons, such as sodium metal or cyclohexane (C6H12), are calledreductants (or reducing agents) because they can cause the reduction of another compound. In the process of donating electrons, a reductant is oxidized. These relationships are summarized in Equation 3.30: Equation 3.30 Saylor URL: http://www. saylor. org/books.\\nquestion: Compounds that are capable of accepting electrons, such as o 2 or f2, are called what? \\nanswer:', 'continuation': 'residues'}, {'context': 'Oxidants and Reductants Compounds that are capable of accepting electrons, such as O 2 or F2, are calledoxidants (or oxidizing agents) because they can oxidize other compounds. In the process of accepting electrons, an oxidant is reduced. Compounds that are capable of donating electrons, such as sodium metal or cyclohexane (C6H12), are calledreductants (or reducing agents) because they can cause the reduction of another compound. In the process of donating electrons, a reductant is oxidized. These relationships are summarized in Equation 3.30: Equation 3.30 Saylor URL: http://www. saylor. org/books.\\nquestion: Compounds that are capable of accepting electrons, such as o 2 or f2, are called what? \\nanswer:', 'continuation': 'Oxygen'}, {'context': 'Oxidants and Reductants Compounds that are capable of accepting electrons, such as O 2 or F2, are calledoxidants (or oxidizing agents) because they can oxidize other compounds. In the process of accepting electrons, an oxidant is reduced. Compounds that are capable of donating electrons, such as sodium metal or cyclohexane (C6H12), are calledreductants (or reducing agents) because they can cause the reduction of another compound. In the process of donating electrons, a reductant is oxidized. These relationships are summarized in Equation 3.30: Equation 3.30 Saylor URL: http://www. saylor. org/books.\\nquestion: Compounds that are capable of accepting electrons, such as o 2 or f2, are called what? \\nanswer:', 'continuation': 'antioxidants'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_prompts(prompts, tokenizer):\n",
        "  encoded_prompts = []\n",
        "  #Loop through and encode prompts based on tokenizer\n",
        "  for prompt in prompts:\n",
        "    context = prompt['context']\n",
        "    continuation = prompt['continuation']\n",
        "    encoded_prompt = tokenizer.encode(context + continuation)\n",
        "    encoded_context = tokenizer.encode(context)\n",
        "    encoded_context_len = len(encoded_context)\n",
        "    encoded_continuation = encoded_prompt[encoded_context_len:]\n",
        "    encoded_prompts.append({'encoded_context': encoded_context, 'encoded_continuation': encoded_continuation})\n",
        "\n",
        "  return encoded_prompts\n",
        "\n",
        "encoded = encode_prompts(prompts, tokenizer)\n",
        "print(encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EjMp7mO0z_m",
        "outputId": "ec81ce2e-d9b9-45c8-ac76-fdd55fc48edf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'encoded_context': [38208, 312, 1187, 290, 2297, 4782, 1187, 3082, 3733, 326, 389, 6007, 286, 12598, 28722, 11, 884, 355, 440, 362, 393, 376, 17, 11, 389, 1444, 1140, 312, 1187, 357, 273, 18762, 2890, 6554, 8, 780, 484, 460, 18762, 1096, 584, 16439, 13, 554, 262, 1429, 286, 12598, 28722, 11, 281, 18762, 415, 318, 5322, 13, 3082, 3733, 326, 389, 6007, 286, 29798, 28722, 11, 884, 355, 21072, 6147, 393, 11700, 78, 33095, 1531, 357, 34, 21, 39, 1065, 828, 389, 1444, 445, 4782, 1187, 357, 273, 8868, 6554, 8, 780, 484, 460, 2728, 262, 7741, 286, 1194, 13061, 13, 554, 262, 1429, 286, 29798, 28722, 11, 257, 2027, 310, 415, 318, 18762, 1143, 13, 2312, 6958, 389, 31880, 287, 7889, 341, 513, 13, 1270, 25, 7889, 341, 513, 13, 1270, 311, 7167, 10289, 25, 2638, 1378, 2503, 13, 910, 4685, 13, 8745, 14, 12106, 13, 198, 25652, 25, 3082, 3733, 326, 389, 6007, 286, 12598, 28722, 11, 884, 355, 267, 362, 393, 277, 17, 11, 389, 1444, 644, 30, 220, 198, 41484, 25], 'encoded_continuation': [1140, 312, 1187]}, {'encoded_context': [38208, 312, 1187, 290, 2297, 4782, 1187, 3082, 3733, 326, 389, 6007, 286, 12598, 28722, 11, 884, 355, 440, 362, 393, 376, 17, 11, 389, 1444, 1140, 312, 1187, 357, 273, 18762, 2890, 6554, 8, 780, 484, 460, 18762, 1096, 584, 16439, 13, 554, 262, 1429, 286, 12598, 28722, 11, 281, 18762, 415, 318, 5322, 13, 3082, 3733, 326, 389, 6007, 286, 29798, 28722, 11, 884, 355, 21072, 6147, 393, 11700, 78, 33095, 1531, 357, 34, 21, 39, 1065, 828, 389, 1444, 445, 4782, 1187, 357, 273, 8868, 6554, 8, 780, 484, 460, 2728, 262, 7741, 286, 1194, 13061, 13, 554, 262, 1429, 286, 29798, 28722, 11, 257, 2027, 310, 415, 318, 18762, 1143, 13, 2312, 6958, 389, 31880, 287, 7889, 341, 513, 13, 1270, 25, 7889, 341, 513, 13, 1270, 311, 7167, 10289, 25, 2638, 1378, 2503, 13, 910, 4685, 13, 8745, 14, 12106, 13, 198, 25652, 25, 3082, 3733, 326, 389, 6007, 286, 12598, 28722, 11, 884, 355, 267, 362, 393, 277, 17, 11, 389, 1444, 644, 30, 220, 198, 41484, 25], 'encoded_continuation': [411, 312, 947]}, {'encoded_context': [38208, 312, 1187, 290, 2297, 4782, 1187, 3082, 3733, 326, 389, 6007, 286, 12598, 28722, 11, 884, 355, 440, 362, 393, 376, 17, 11, 389, 1444, 1140, 312, 1187, 357, 273, 18762, 2890, 6554, 8, 780, 484, 460, 18762, 1096, 584, 16439, 13, 554, 262, 1429, 286, 12598, 28722, 11, 281, 18762, 415, 318, 5322, 13, 3082, 3733, 326, 389, 6007, 286, 29798, 28722, 11, 884, 355, 21072, 6147, 393, 11700, 78, 33095, 1531, 357, 34, 21, 39, 1065, 828, 389, 1444, 445, 4782, 1187, 357, 273, 8868, 6554, 8, 780, 484, 460, 2728, 262, 7741, 286, 1194, 13061, 13, 554, 262, 1429, 286, 29798, 28722, 11, 257, 2027, 310, 415, 318, 18762, 1143, 13, 2312, 6958, 389, 31880, 287, 7889, 341, 513, 13, 1270, 25, 7889, 341, 513, 13, 1270, 311, 7167, 10289, 25, 2638, 1378, 2503, 13, 910, 4685, 13, 8745, 14, 12106, 13, 198, 25652, 25, 3082, 3733, 326, 389, 6007, 286, 12598, 28722, 11, 884, 355, 267, 362, 393, 277, 17, 11, 389, 1444, 644, 30, 220, 198, 41484, 25], 'encoded_continuation': [46, 5431, 5235]}, {'encoded_context': [38208, 312, 1187, 290, 2297, 4782, 1187, 3082, 3733, 326, 389, 6007, 286, 12598, 28722, 11, 884, 355, 440, 362, 393, 376, 17, 11, 389, 1444, 1140, 312, 1187, 357, 273, 18762, 2890, 6554, 8, 780, 484, 460, 18762, 1096, 584, 16439, 13, 554, 262, 1429, 286, 12598, 28722, 11, 281, 18762, 415, 318, 5322, 13, 3082, 3733, 326, 389, 6007, 286, 29798, 28722, 11, 884, 355, 21072, 6147, 393, 11700, 78, 33095, 1531, 357, 34, 21, 39, 1065, 828, 389, 1444, 445, 4782, 1187, 357, 273, 8868, 6554, 8, 780, 484, 460, 2728, 262, 7741, 286, 1194, 13061, 13, 554, 262, 1429, 286, 29798, 28722, 11, 257, 2027, 310, 415, 318, 18762, 1143, 13, 2312, 6958, 389, 31880, 287, 7889, 341, 513, 13, 1270, 25, 7889, 341, 513, 13, 1270, 311, 7167, 10289, 25, 2638, 1378, 2503, 13, 910, 4685, 13, 8745, 14, 12106, 13, 198, 25652, 25, 3082, 3733, 326, 389, 6007, 286, 12598, 28722, 11, 884, 355, 267, 362, 393, 277, 17, 11, 389, 1444, 644, 30, 220, 198, 41484, 25], 'encoded_continuation': [415, 26294, 1187]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09fde66c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c495cbb9-a4d8-41c9-89e7-f04c45604d7c"
      },
      "source": [
        "device = torch.device('cpu')\n",
        "model.to(device)\n",
        "\n",
        "def get_log_liklihood(encoded_prompts, model):\n",
        "  results = []\n",
        "  for encoded_prompt in encoded_prompts:\n",
        "    encoded_context = encoded_prompt['encoded_context']\n",
        "    encoded_continuation = encoded_prompt['encoded_continuation']\n",
        "    #Convert the input to a tensor to be passed to the model\n",
        "    inp = torch.tensor(\n",
        "        (encoded_context + encoded_continuation)[-(max_length + 1) :][:-1],\n",
        "        dtype=torch.long,\n",
        "        device=device,\n",
        "    )\n",
        "    # Add a batch dimension to the input tensor\n",
        "    inp = inp.unsqueeze(0)\n",
        "\n",
        "    # Pass inputs and get logits from model response\n",
        "    #tock.no_grad() disables gradient calculation which is not needed for eval\n",
        "    with torch.no_grad():\n",
        "      logits = model(inp).logits\n",
        "\n",
        "    # Normalize logits vocab dimension using log_softmax\n",
        "    log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
        "\n",
        "    #Convert continuation tokens to a tensor\n",
        "    cont_toks = torch.tensor(encoded_continuation, dtype=torch.long, device=device).unsqueeze(0)\n",
        "    # Slice logits to get the logits for the continuation tokens\n",
        "    # logits has the shape [batch_size, sequence_length, vocab]\n",
        "    # Slice the sequence from the end of the sequence starting at the length of tokens in the continuation sequence\n",
        "    log_probs_for_cont = log_probs[:, -cont_toks.shape[1] :, :]\n",
        "    #Get most likely tokens from logits vocabulary for sequence (vocab is the last dimension)\n",
        "    greedy_tokens = log_probs_for_cont.argmax(dim=-1)\n",
        "\n",
        "    # Get the log probabilities of the actual continuation tokens\n",
        "    compare_log_probs = torch.gather(log_probs_for_cont, 2, cont_toks.unsqueeze(-1)).squeeze(-1)\n",
        "\n",
        "\n",
        "    # Sum the log likelihood for the continuation tokens\n",
        "    # Sum instead of multiply because log(a*b) = log(a) + log(b)\n",
        "    log_likelihood = float(compare_log_probs.sum())\n",
        "    results.append(log_likelihood)\n",
        "\n",
        "  return results\n",
        "\n",
        "log_likelihoods = get_log_liklihood(encoded, model)\n",
        "print(log_likelihoods)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-8.289290428161621, -15.653117179870605, -12.925821304321289, -13.8721342086792]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "581853bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "754d83c8-1b05-4046-9e6d-f7e9848bf069"
      },
      "source": [
        "# Set a limit for the number of questions to process\n",
        "LIMIT = 10\n",
        "\n",
        "#Evaluate\n",
        "limited_dataset = dataset.select(range(LIMIT))\n",
        "\n",
        "results = []\n",
        "for sample in tqdm(limited_dataset):\n",
        "    prompts = generate_prompts(sample)\n",
        "    encoded = encode_prompts(prompts, tokenizer)\n",
        "    log_likelihoods = get_log_liklihood(encoded, model)\n",
        "    # Based on generating prompts we set the correct answer to be the first one\n",
        "    correct_answer_log_likelihood = log_likelihoods[0]\n",
        "    distractor_log_likelihoods = [log_liklihood for log_liklihood in log_likelihoods[1:]]\n",
        "\n",
        "    # Determine if the correct answer has the highest log likelihood\n",
        "    is_correct = all(correct_answer_log_likelihood > distractor_ll for distractor_ll in distractor_log_likelihoods)\n",
        "\n",
        "    results.append({\n",
        "        'question': sample['question'],\n",
        "        'correct_answer': sample['correct_answer'],\n",
        "        'log_likelihood_correct': correct_answer_log_likelihood,\n",
        "        'log_likelihood_distractors': distractor_log_likelihoods,\n",
        "        'is_correct': is_correct\n",
        "    })\n",
        "\n",
        "# Print results for each question\n",
        "for i, result in enumerate(results):\n",
        "    print(f\"Question: {result['question']}\")\n",
        "    print(f\"Correct Answer: {result['correct_answer']} (Log Likelihood: {result['log_likelihood_correct']})\")\n",
        "    print(f\"Distractor Log Likelihoods: {result['log_likelihood_distractors']}\")\n",
        "    print(f\"Model Predicted Correct: {result['is_correct']}\\n\")\n",
        "    print(\"-\" * 20)\n",
        "\n",
        "# Calculate overall accuracy\n",
        "accuracy = sum(r['is_correct'] for r in results) / len(results)\n",
        "print(f\"Overall Accuracy on the first {LIMIT} examples: {accuracy:.2f}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:41<00:00,  4.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Compounds that are capable of accepting electrons, such as o 2 or f2, are called what?\n",
            "Correct Answer: oxidants (Log Likelihood: -8.289290428161621)\n",
            "Distractor Log Likelihoods: [-15.653117179870605, -12.925821304321289, -13.8721342086792]\n",
            "Model Predicted Correct: True\n",
            "\n",
            "--------------------\n",
            "Question: What term in biotechnology means a genetically exact copy of an organism?\n",
            "Correct Answer: clone (Log Likelihood: -14.674302101135254)\n",
            "Distractor Log Likelihoods: [-15.728692054748535, -15.405716896057129, -17.5056095123291]\n",
            "Model Predicted Correct: True\n",
            "\n",
            "--------------------\n",
            "Question: Vertebrata are characterized by the presence of what?\n",
            "Correct Answer: backbone (Log Likelihood: -13.691313743591309)\n",
            "Distractor Log Likelihoods: [-19.18093490600586, -15.642292976379395, -15.81669807434082]\n",
            "Model Predicted Correct: True\n",
            "\n",
            "--------------------\n",
            "Question: What is the height above or below sea level called?\n",
            "Correct Answer: elevation (Log Likelihood: -11.339323997497559)\n",
            "Distractor Log Likelihoods: [-16.406641006469727, -11.609243392944336, -15.257266998291016]\n",
            "Model Predicted Correct: True\n",
            "\n",
            "--------------------\n",
            "Question: Ice cores, varves and what else indicate the environmental conditions at the time of their creation?\n",
            "Correct Answer: tree rings (Log Likelihood: -14.335933685302734)\n",
            "Distractor Log Likelihoods: [-19.95759391784668, -15.560441017150879, -21.414222717285156]\n",
            "Model Predicted Correct: True\n",
            "\n",
            "--------------------\n",
            "Question: What chemical signals in plants control different processes?\n",
            "Correct Answer: plant hormones (Log Likelihood: -11.545206069946289)\n",
            "Distractor Log Likelihoods: [-23.122644424438477, -20.797531127929688, -15.584097862243652]\n",
            "Model Predicted Correct: True\n",
            "\n",
            "--------------------\n",
            "Question: Meiosis is part of the process of gametogenesis, which is the production of what?\n",
            "Correct Answer: sperm and eggs (Log Likelihood: -10.438736915588379)\n",
            "Distractor Log Likelihoods: [-15.07374095916748, -20.888568878173828, -18.416419982910156]\n",
            "Model Predicted Correct: True\n",
            "\n",
            "--------------------\n",
            "Question: Which type of tree is dominant in temperate forests?\n",
            "Correct Answer: deciduous (Log Likelihood: -12.686229705810547)\n",
            "Distractor Log Likelihoods: [-17.228883743286133, -16.060091018676758, -19.945812225341797]\n",
            "Model Predicted Correct: True\n",
            "\n",
            "--------------------\n",
            "Question: What kind of viscosity is found in long-chain hydrocarbons?\n",
            "Correct Answer: highly viscous (Log Likelihood: -14.631791114807129)\n",
            "Distractor Log Likelihoods: [-18.879924774169922, -13.177200317382812, -16.882144927978516]\n",
            "Model Predicted Correct: False\n",
            "\n",
            "--------------------\n",
            "Question: Ionic compounds have strong electrostatic attractions between oppositely charged ions in this?\n",
            "Correct Answer: regular array (Log Likelihood: -17.129459381103516)\n",
            "Distractor Log Likelihoods: [-28.24005889892578, -23.693574905395508, -26.655677795410156]\n",
            "Model Predicted Correct: True\n",
            "\n",
            "--------------------\n",
            "Overall Accuracy on the first 10 examples: 0.90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}